# Music Generation through Semaphore-Inspired Arm Gestures
Ever heard of dancing to the beat of your own drum? What if you could beat your drum according to your own dance?

This gesture-based music generation tool synthesizes music in real-time based on semaphore-inspired arm movements performed by the user. Joint angles are identified using the TensorFlow PoseNet model. Based on the userâ€™s joint angles, the semaphore-based gesture is mapped gesture is mapped to a corresponding musical note.

Attributions:
https://github.com/ygev/semaphore
